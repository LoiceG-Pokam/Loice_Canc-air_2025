import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from scipy.stats import chi2_contingency
from sklearn.preprocessing import StandardScaler
from scipy.stats import ttest_ind, mannwhitneyu
from tqdm import tqdm
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

from sklearn.neighbors import NearestNeighbors

warnings.filterwarnings('ignore')

class CaseControlMatcher:
    """
    Classe optimis√©e pour l'appariement cas-t√©moins avec d√©finition flexible des cas
    et analyse compl√®te des facteurs confondants avant appariement.
    """

    def __init__(self, n_jobs=-1):
        self.n_jobs = n_jobs if n_jobs != -1 else mp.cpu_count()
        self.confounder_results = None
        self.matching_quality = None
        self.df_matched_final = pd.DataFrame()
        
    def define_cases_controls(self, df, case_definition, control_definition=None):
        """
        D√©finit les cas et t√©moins selon des crit√®res flexibles.
        
        Args:
            df: DataFrame
            case_definition: dict avec les crit√®res pour d√©finir les cas
                Exemples:
                - {'statut_deces_a_letude': 'oui'}
                - {'EM': ['aplasie', 'embolie']}
                - {'statut_deces_a_letude': 'oui', 'EM': ['aplasie']}
            control_definition: dict pour d√©finir les t√©moins (optionnel)
                Si None, les t√©moins sont tous ceux qui ne sont pas des cas
        """
        print(f"\n{'='*60}")
        print("D√âFINITION DES CAS ET T√âMOINS")
        print(f"{'='*60}")
        
        # Cr√©ation de la colonne de statut cas/t√©moin
        df = df.copy()
        df['is_case'] = False
        
        # Application des crit√®res de cas
        case_mask = pd.Series([True] * len(df), index=df.index)
        
        for column, values in case_definition.items():
            if column not in df.columns:
                print(f"‚ö†Ô∏è Attention: Colonne '{column}' non trouv√©e dans le DataFrame")
                continue
                
            if isinstance(values, list):
                column_mask = df[column].isin(values)
            else:
                column_mask = (df[column] == values)
                
            case_mask = case_mask & column_mask
            
        df.loc[case_mask, 'is_case'] = True
        
        # Application des crit√®res de t√©moins si sp√©cifi√©s
        if control_definition:
            control_mask = pd.Series([True] * len(df), index=df.index)
            for column, values in control_definition.items():
                if column not in df.columns:
                    continue
                if isinstance(values, list):
                    column_mask = df[column].isin(values)
                else:
                    column_mask = (df[column] == values)
                control_mask = control_mask & column_mask
            
            # Seuls les individus satisfaisant les crit√®res de t√©moins ET n'√©tant pas des cas
            df = df[control_mask | case_mask].copy()
            df.loc[control_mask & ~case_mask, 'is_case'] = False
        
        n_cases = df['is_case'].sum()
        n_controls = (~df['is_case']).sum()
        
        print(f"Crit√®res de cas appliqu√©s: {case_definition}")
        if control_definition:
            print(f"Crit√®res de t√©moins appliqu√©s: {control_definition}")
        else:
            print("T√©moins: tous les individus ne satisfaisant pas les crit√®res de cas")
            
        print(f"\nR√©sultats:")
        print(f"- Cas identifi√©s: {n_cases}")
        print(f"- T√©moins identifi√©s: {n_controls}")
        print(f"- Ratio cas/t√©moins: 1:{n_controls/n_cases:.1f}" if n_cases > 0 else "- Ratio: impossible √† calculer (0 cas)")
        
        return df

    def _statistical_test_association(self, df, var, outcome_var='is_case'):
        """
        Effectue un test statistique appropri√© selon le type de variable.
        """
        try:
            # Supprimer les valeurs manquantes
            temp_df = df[[var, outcome_var]].dropna()
            if len(temp_df) < 50:
                return {'error': 'Insufficient data', 'n_obs': len(temp_df)}
            
            cases = temp_df[temp_df[outcome_var] == True][var]
            controls = temp_df[temp_df[outcome_var] == False][var]
            
            if len(cases) == 0 or len(controls) == 0:
                return {'error': 'No cases or controls', 'n_cases': len(cases), 'n_controls': len(controls)}
            
            result = {'variable': var, 'n_obs': len(temp_df), 'n_cases': len(cases), 'n_controls': len(controls)}
            
            # Test selon le type de variable
            if pd.api.types.is_numeric_dtype(temp_df[var]):
                # Variable continue : t-test ou Mann-Whitney U
                if cases.nunique() <= 10 or controls.nunique() <= 10:
                    # Peu de valeurs uniques, traiter comme cat√©gorielle
                    crosstab = pd.crosstab(temp_df[var], temp_df[outcome_var])
                    if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:
                        chi2, p_value, _, _ = chi2_contingency(crosstab)
                        result.update({
                            'test_type': 'chi2',
                            'test_statistic': chi2,
                            'p_value': p_value,
                            'effect_size': np.sqrt(chi2 / len(temp_df))
                        })
                    else:
                        result['error'] = 'Insufficient variance for chi2'
                else:
                    # Test de normalit√© simple (Shapiro n'est pas fiable sur de gros √©chantillons)
                    try:
                        # T-test si les tailles d'√©chantillon sont raisonnables
                        if len(cases) > 5000 or len(controls) > 5000:
                            # Mann-Whitney U pour de gros √©chantillons
                            statistic, p_value = mannwhitneyu(cases, controls, alternative='two-sided')
                            result.update({
                                'test_type': 'mannwhitney',
                                'test_statistic': statistic,
                                'p_value': p_value,
                                'cases_median': cases.median(),
                                'controls_median': controls.median(),
                                'effect_size': abs(cases.median() - controls.median()) / temp_df[var].std()
                            })
                        else:
                            statistic, p_value = ttest_ind(cases, controls)
                            result.update({
                                'test_type': 'ttest',
                                'test_statistic': statistic,
                                'p_value': p_value,
                                'cases_mean': cases.mean(),
                                'controls_mean': controls.mean(),
                                'effect_size': abs(cases.mean() - controls.mean()) / temp_df[var].std()
                            })
                    except Exception:
                        # Fallback sur Mann-Whitney
                        statistic, p_value = mannwhitneyu(cases, controls, alternative='two-sided')
                        result.update({
                            'test_type': 'mannwhitney_fallback',
                            'test_statistic': statistic,
                            'p_value': p_value,
                            'cases_median': cases.median(),
                            'controls_median': controls.median()
                        })
            else:
                # Variable cat√©gorielle : Chi2
                crosstab = pd.crosstab(temp_df[var], temp_df[outcome_var])
                if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:
                    chi2, p_value, _, expected = chi2_contingency(crosstab)
                    # V√©rifier les conditions du chi2
                    min_expected = expected.min()
                    result.update({
                        'test_type': 'chi2',
                        'test_statistic': chi2,
                        'p_value': p_value,
                        'effect_size': np.sqrt(chi2 / len(temp_df)),
                        'min_expected_freq': min_expected,
                        'chi2_valid': min_expected >= 5
                    })
                else:
                    result['error'] = 'Insufficient variance for chi2'
            
            # Calcul de l'AUC pour comparaison
            try:
                if pd.api.types.is_numeric_dtype(temp_df[var]):
                    X = temp_df[[var]]
                    y = temp_df[outcome_var].astype(int)
                    if X[var].nunique() > 1:
                        model = LogisticRegression(max_iter=1000, solver='liblinear')
                        model.fit(X, y)
                        y_pred_proba = model.predict_proba(X)[:, 1]
                        auc = roc_auc_score(y, y_pred_proba)
                        result['auc'] = auc
                        result['or'] = np.exp(model.coef_[0][0])
            except Exception:
                pass
                
            return result
            
        except Exception as e:
            return {'error': f'Statistical test failed: {str(e)}', 'variable': var}

    def analyze_confounders(self, df, potential_confounders, outcome_var='is_case', 
                            significance_threshold=0.05, effect_size_threshold=0.1):
        """
        Analyse tous les facteurs confondants potentiels avec tests statistiques appropri√©s.
        """
        print(f"\n{'='*60}")
        print("ANALYSE COMPL√àTE DES FACTEURS CONFONDANTS")
        print(f"{'='*60}")
        print(f"Variables √† analyser: {len(potential_confounders)}")
        print(f"Seuil de significativit√©: {significance_threshold}")
        print(f"Seuil de taille d'effet: {effect_size_threshold}")
        
        results = []
        
        # Analyse en parall√®le pour optimiser le temps
        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
            future_to_var = {
                executor.submit(self._statistical_test_association, df, var, outcome_var): var 
                for var in potential_confounders if var in df.columns
            }
            
            # Ajout de tqdm ici
            for future in tqdm(as_completed(future_to_var), 
                               total=len(future_to_var), 
                               desc="Analyse confondants"):
                var = future_to_var[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    results.append({'variable': var, 'error': f'Execution error: {str(e)}'})
        
        # Conversion en DataFrame pour l'analyse
        results_df = pd.DataFrame(results)
        
        # Identification des confondants significatifs
        confounders_identified = []
        
        print(f"\n{'='*50}")
        print("R√âSULTATS DES TESTS STATISTIQUES")
        print(f"{'='*50}")
        
        for _, row in results_df.iterrows():
            if 'error' in row and pd.notna(row['error']):
                print(f"‚ùå {row['variable']}: {row['error']}")
                continue
                
            var = row['variable']
            p_val = row.get('p_value', 1.0)
            effect_size = row.get('effect_size', 0.0)
            test_type = row.get('test_type', 'unknown')
            
            is_significant = p_val < significance_threshold
            has_effect = effect_size > effect_size_threshold
            
            status = "üî¥ CONFONDANT" if (is_significant and has_effect) else "‚ö™ Non significatif"
            
            print(f"{status} {var}:")
            print(f"   Test: {test_type.upper()}")
            print(f"   p-value: {p_val:.4f}")
            print(f"   Taille d'effet: {effect_size:.4f}")
            
            if test_type == 'ttest':
                print(f"   Moyennes - Cas: {row.get('cases_mean', 'N/A'):.2f}, T√©moins: {row.get('controls_mean', 'N/A'):.2f}")
            elif test_type in ['mannwhitney', 'mannwhitney_fallback']:
                print(f"   M√©dianes - Cas: {row.get('cases_median', 'N/A'):.2f}, T√©moins: {row.get('controls_median', 'N/A'):.2f}")
            elif test_type == 'chi2':
                print(f"   Chi2 valide: {row.get('chi2_valid', 'N/A')}")
                
            if 'auc' in row:
                print(f"   AUC: {row['auc']:.3f}")
            if 'or' in row:
                print(f"   OR: {row['or']:.3f}")
                
            print()
            
            if is_significant and has_effect:
                confounders_identified.append(var)
        
        print(f"\nüéØ FACTEURS CONFONDANTS IDENTIFI√âS ({len(confounders_identified)}):")
        for conf in confounders_identified:
            print(f"   ‚Ä¢ {conf}")
            
        self.confounder_results = {
            'results_df': results_df,
            'confounders_identified': confounders_identified,
            'significance_threshold': significance_threshold,
            'effect_size_threshold': effect_size_threshold,
            'n_cases': df[outcome_var].sum(),
            'n_controls': (~df[outcome_var]).sum()
        }
        
        return self.confounder_results

    def match_cases_controls_optimized(self, df, matching_vars, date_column_for_reference="date_deces"):
        """
        Apparie chaque t√©moin au cas le plus proche, permettant √† un cas de
        servir de r√©f√©rence pour plusieurs t√©moins.

        Args:
            df (pd.DataFrame): DataFrame contenant une colonne 'is_case'
            matching_vars (list): Variables √† utiliser pour l'appariement.
            date_column_for_reference (str): Nom de la colonne de date √† utiliser comme date de r√©f√©rence.

        Returns:
            pd.DataFrame: DataFrame contenant tous les t√©moins avec leur date_reference et cas_apparie,
                          plus les cas originaux avec leur propre date_reference.
        """
        print(f"\n{'='*60}")
        print("APPARIEMENT T√âMOIN-VERS-CAS (PROPAGATION DE DATE)")
        print(f"{'='*60}")

        cases_df = df[df["is_case"] == True].copy()
        controls_df = df[df["is_case"] == False].copy()

        if cases_df.empty:
            print("‚ùå Aucun cas trouv√©. Impossible d'apparier les t√©moins. Retourne un DataFrame vide.")
            return pd.DataFrame()
        
        if controls_df.empty:
            print("‚ö†Ô∏è Aucun t√©moin trouv√©. Retourne seulement les cas.")
            # Si pas de t√©moins, on retourne juste les cas avec leur date de r√©f√©rence
            if date_column_for_reference in cases_df.columns:
                cases_df["date_reference"] = cases_df[date_column_for_reference]
            else:
                cases_df["date_reference"] = pd.NaT # G√©rer les dates manquantes
            cases_df["cas_apparie"] = None
            # On ajoute ces colonnes pour la coh√©rence m√™me si pas de t√©moins
            cases_df["matched_control_ids"] = None
            return cases_df

        if date_column_for_reference not in cases_df.columns:
            print(f"‚ùå La colonne de date de r√©f√©rence '{date_column_for_reference}' est introuvable dans les donn√©es des cas. Assurez-vous qu'elle existe.")
            return pd.DataFrame()

        # Pr√©paration des donn√©es pour NearestNeighbors
        df_temp_for_nn = df.copy()
        
        numeric_vars = [v for v in matching_vars if v in df_temp_for_nn.columns and pd.api.types.is_numeric_dtype(df_temp_for_nn[v])]
        categorical_vars = [v for v in matching_vars if v in df_temp_for_nn.columns and not pd.api.types.is_numeric_dtype(df_temp_for_nn[v])]

        # Scaling des variables num√©riques
        if numeric_vars:
            scaler = StandardScaler()
            df_temp_for_nn[numeric_vars] = scaler.fit_transform(df_temp_for_nn[numeric_vars])
            print(f"‚úÖ Variables num√©riques ({len(numeric_vars)}) scal√©es.")
        else:
            print("‚ÑπÔ∏è Aucune variable num√©rique √† scaler parmi les variables d'appariement.")

        # One-hot encoding des variables cat√©gorielles
        encoded_categorical_cols = []
        if categorical_vars:
            df_temp_for_nn_dummies = pd.get_dummies(df_temp_for_nn, columns=categorical_vars, drop_first=True, prefix=categorical_vars)
            encoded_categorical_cols = [col for col in df_temp_for_nn_dummies.columns if any(col.startswith(cat_v + '_') for cat_v in categorical_vars)]
            df_temp_for_nn = df_temp_for_nn_dummies
            print(f"‚úÖ Variables cat√©gorielles ({len(categorical_vars)}) encod√©es ({len(encoded_categorical_cols)} nouvelles colonnes).")
        else:
            print("‚ÑπÔ∏è Aucune variable cat√©gorielle √† encoder parmi les variables d'appariement.")

        vars_for_nn_model = numeric_vars + encoded_categorical_cols

        if not vars_for_nn_model:
            print("‚ùå Aucune variable valide trouv√©e pour l'appariement apr√®s le traitement. Veuillez v√©rifier `matching_vars`.")
            return pd.DataFrame()

        # Maintenant, le mod√®le NN est entra√Æn√© sur les CAS
        cases_encoded = df_temp_for_nn.loc[cases_df.index, vars_for_nn_model]
        controls_encoded = df_temp_for_nn.loc[controls_df.index, vars_for_nn_model]
        
        if cases_encoded.empty or controls_encoded.empty:
            print("‚ö†Ô∏è Les DataFrames encod√©s pour l'appariement sont vides apr√®s la s√©lection des colonnes. V√©rifiez vos donn√©es et variables de matching.")
            return pd.DataFrame()

        print(f"\n‚öôÔ∏è Apprentissage NearestNeighbors sur les cas ({len(cases_encoded)} cas) avec {len(vars_for_nn_model)} variables.")
        nn = NearestNeighbors(n_neighbors=1, algorithm="auto") # Chaque t√©moin cherche 1 cas le plus proche
        nn.fit(cases_encoded)

        print(f"üîÑ Recherche du cas le plus proche pour chaque t√©moin ({len(controls_encoded)} t√©moins).")
        # distances, indices = nn.kneighbors(controls_encoded) # Ancienne ligne, cause erreur d'attribut si contr√¥le est vide
        distances, indices = nn.kneighbors(controls_encoded)

        # Cr√©ation des colonnes d'appariement pour les t√©moins
        matched_case_ids_for_controls = []
        
        # Le `indices` retourn√© par kneighbors est un tableau d'index dans `cases_encoded`
        # On doit le mapper aux index originaux des cas pour r√©cup√©rer les infos compl√®tes.
        case_original_indices = cases_df.index.tolist()

        for i in tqdm(range(len(controls_df)), desc="Appariement des t√©moins"):
            control_original_index = controls_df.index[i]
            
            # L'index du cas le plus proche dans le DataFrame `cases_encoded`
            closest_case_encoded_idx = indices[i][0]
            
            # L'index original du cas le plus proche dans le DataFrame `df`
            closest_case_original_idx = case_original_indices[closest_case_encoded_idx]
            
            # L'ID pseudo_provisoire du cas le plus proche
            closest_case_id = df.loc[closest_case_original_idx, "pseudo_provisoire"]
            
            matched_case_ids_for_controls.append(closest_case_id)

        # Ajouter les colonnes d'appariement aux t√©moins
        controls_df["cas_apparie"] = matched_case_ids_for_controls
        controls_df["matched_case_id"] = matched_case_ids_for_controls # Alias pour clart√©
        
        # Les t√©moins n'ont pas de 'matched_control_ids' au sens o√π les cas en auraient
        controls_df["matched_control_ids"] = None 

        # üîπ Cr√©er la colonne date_reference pour les cas et t√©moins
        # Pour les cas, la date de r√©f√©rence est leur propre date d'√©v√©nement
        if date_column_for_reference in cases_df.columns:
            cases_df["date_reference"] = cases_df[date_column_for_reference]
        else:
            print(f"‚ö†Ô∏è La colonne '{date_column_for_reference}' n'est pas trouv√©e dans les cas pour la date de r√©f√©rence. Les dates de r√©f√©rence des cas seront vides.")
            cases_df["date_reference"] = pd.NaT 
        cases_df["cas_apparie"] = None # Les cas ne sont pas "appari√©s √† un cas" dans cette logique
        
        # Pour les t√©moins, la date de r√©f√©rence est celle du cas appari√©
        case_id_to_date_reference = cases_df.set_index("pseudo_provisoire")["date_reference"].to_dict()
        controls_df["date_reference"] = controls_df["cas_apparie"].map(case_id_to_date_reference)


        # Les cas ont besoin d'une colonne matched_control_ids pour la coh√©rence
        # Mais dans cette nouvelle dynamique, un cas peut √™tre appari√© √† plusieurs t√©moins.
        # Nous devons donc regrouper les t√©moins par cas appari√©.
        temp_matched_control_ids = controls_df.groupby("cas_apparie")["pseudo_provisoire"].apply(lambda x: ','.join(map(str, x))).to_dict()
        cases_df["matched_control_ids"] = cases_df["pseudo_provisoire"].map(temp_matched_control_ids)

        # üîπ Concat√©nation finale
        # On inclut tous les cas et tous les t√©moins, car chaque t√©moin a trouv√© un cas de r√©f√©rence.
        self.df_matched_final = pd.concat([cases_df, controls_df], ignore_index=True)
        print(f"‚úÖ Appariement termin√©. {len(cases_df)} cas et {len(controls_df)} t√©moins ont √©t√© inclus.")

        return self.df_matched_final

    def _check_matching_quality_optimized(self, df_cases_matched, df_controls_matched, matching_vars):
        """
        V√©rification optimis√©e de la qualit√© d'appariement.
        Cette m√©thode reste inchang√©e, mais son interpr√©tation change :
        elle montre si les t√©moins *appari√©s* sont similaires aux cas *qui les ont servis de r√©f√©rence*.
        C'est moins une v√©rification d'√©quilibre de groupes que de pertinence de l'appariement.
        """
        print(f"\n{'='*40}")
        print("QUALIT√â DE L'APPARIEMENT (SIMILARIT√â T√âMOINS-CAS DE R√âF√âRENCE)")
        print(f"{'='*40}")
        
        if df_cases_matched.empty or df_controls_matched.empty:
            print("‚ö†Ô∏è Aucun cas ou t√©moin pour v√©rifier la qualit√©.")
            return {}

        quality_results = {}
        
        for var in matching_vars:
            if var not in df_cases_matched.columns or var not in df_controls_matched.columns:
                print(f"‚ö†Ô∏è Variable '{var}' non trouv√©e dans les DataFrames appari√©s, ignor√©e pour le contr√¥le qualit√©.")
                continue
                
            print(f"\nüìä {var.upper()}:")
            
            if pd.api.types.is_numeric_dtype(df_cases_matched[var]):
                # Variables num√©riques
                case_mean = df_cases_matched[var].mean()
                control_mean = df_controls_matched[var].mean()
                case_std = df_cases_matched[var].std()
                control_std = df_controls_matched[var].std()
                
                diff = abs(case_mean - control_mean)
                
                print(f"   Cas:    {case_mean:.2f} ¬± {case_std:.2f}")
                print(f"   T√©moins: {control_mean:.2f} ¬± {control_std:.2f}")
                print(f"   Diff√©rence: {diff:.2f}")
                
                quality_results[var] = {
                    'type': 'numeric',
                    'difference': diff,
                    'case_mean': case_mean,
                    'control_mean': control_mean
                }
                
            else:
                # Variables cat√©gorielles
                case_props = df_cases_matched[var].value_counts(normalize=True)
                control_props = df_controls_matched[var].value_counts(normalize=True)
                
                all_categories = set(case_props.index) | set(control_props.index)
                max_diff = 0
                
                print("   Proportions:")
                for cat in sorted(all_categories, key=str): # Utiliser str() pour trier les types mixtes
                    case_prop = case_props.get(cat, 0)
                    control_prop = control_props.get(cat, 0)
                    diff = abs(case_prop - control_prop)
                    max_diff = max(max_diff, diff)
                    
                    print(f"     {cat}: Cas {case_prop:.1%}, T√©moins {control_prop:.1%} (Œî{diff:.1%})")
                
                quality_results[var] = {
                    'type': 'categorical',
                    'max_difference': max_diff
                }
        
        # √âvaluation globale
        good_quality = True
        for var, results in quality_results.items():
            if results['type'] == 'numeric' and results['difference'] > 2: # Seuil √† ajuster
                good_quality = False
            elif results['type'] == 'categorical' and results['max_difference'] > 0.15: # Seuil √† ajuster
                good_quality = False
        
        status = "‚úÖ EXCELLENTE" if good_quality else "‚ö†Ô∏è √Ä AM√âLIORER"
        print(f"\nüéØ QUALIT√â GLOBALE: {status}")
        
        self.matching_quality = quality_results
        return quality_results

    def run_complete_analysis(self, df, case_definition, potential_confounders,
                              control_definition=None, auto_matching_vars=True,
                              manual_matching_vars=None, significance_threshold=0.05,
                              effect_size_threshold=0.1, date_column="date_deces"):
        """
        Analyse compl√®te optimis√©e : d√©finition des cas, analyse des confondants, appariement.
        Note: `max_controls_per_case` n'est plus pertinent pour l'appariement witness-to-case.
        """
        print("üöÄ ANALYSE COMPL√àTE CAS-T√âMOINS OPTIMIS√âE (PROPAGATION DE DATE)")
        print("="*80)
        
        # √âtape 1: D√©finition des cas et t√©moins
        df_with_cases = self.define_cases_controls(df, case_definition, control_definition)
        
        if df_with_cases['is_case'].sum() == 0:
            print("‚ùå Aucun cas identifi√© avec les crit√®res fournis. Impossible de trouver des dates de r√©f√©rence pour les t√©moins.")
            return None
            
        # √âtape 2: Analyse des confondants
        # Cette √©tape est toujours pertinente pour identifier les variables importantes pour l'appariement.
        confounder_analysis = self.analyze_confounders(
            df_with_cases, 
            potential_confounders,
            significance_threshold=significance_threshold,
            effect_size_threshold=effect_size_threshold
        )
        
        # √âtape 3: D√©termination des variables d'appariement
        if auto_matching_vars and confounder_analysis and confounder_analysis['confounders_identified']:
            matching_variables = confounder_analysis['confounders_identified']
            print(f"\nüí° Variables d'appariement automatiques: {matching_variables}")
        elif manual_matching_vars:
            matching_variables = manual_matching_vars
            print(f"\nüí° Variables d'appariement manuelles: {matching_variables}")
        else:
            print("‚ö†Ô∏è Aucun confondant identifi√© ou `auto_matching_vars` est False et pas de variables manuelles. Utilisation de variables par d√©faut (age_a_letude, patient_sexe si pr√©sentes).")
            matching_variables = [var for var in ['age_a_letude', 'patient_sexe'] if var in df_with_cases.columns]
        
        # S'assurer que la colonne de date de r√©f√©rence existe
        if date_column not in df_with_cases.columns:
            print(f"‚ùå Erreur: La colonne '{date_column}' sp√©cifi√©e pour la date de r√©f√©rence est introuvable dans le DataFrame. Veuillez la corriger.")
            return None

        # √âtape 4: Appariement optimis√© (tous les t√©moins appari√©s √† un cas)
        df_matched = self.match_cases_controls_optimized(
            df_with_cases,
            matching_variables,
            date_column_for_reference=date_column
        )
        
        # √âtape 5: V√©rification de la qualit√© d'appariement (optionnel)
        if not df_matched.empty:
            # Pour la v√©rification de qualit√©, on compare les t√©moins AVEC les cas qui leur ont servi de r√©f√©rence.
            # On prend tous les cas qui ont √©t√© utilis√©s comme r√©f√©rence.
            # Pour les t√©moins, on ne prend que ceux qui ont √©t√© effectivement appari√©s.
            cases_for_quality_check = df_matched[df_matched['is_case'] == True].copy()
            controls_for_quality_check = df_matched[df_matched['is_case'] == False].copy()
            
            self._check_matching_quality_optimized(cases_for_quality_check, controls_for_quality_check, matching_variables)
        else:
            print("Aucun appariement r√©ussi pour v√©rifier la qualit√©.")


        results = {
            'df_original': df,
            'df_with_case_definition': df_with_cases,
            'df_matched_final': df_matched,
            'case_definition': case_definition,
            'control_definition': control_definition,
            'confounder_analysis': confounder_analysis,
            'matching_variables': matching_variables,
            'matching_quality': self.matching_quality
        }
        
        print(f"\n‚úÖ ANALYSE COMPL√àTE TERMIN√âE")
        print("="*40)
        
        return results



# # src/matching.py
# import pandas as pd
# import numpy as np

# class CaseControlMatcher:
#     def score_matching(self, cas, temoin):
#         score = 0
#         score += abs((cas['age_a_letude'] - temoin['age_a_letude']) ** 2)
#         score += 100 * (cas['patient_sexe'] != temoin['patient_sexe'])
#         score += 100 * (cas['patho'] != temoin['patho'])
#         score += 100 * (cas['CODE_DEPT'] != temoin['CODE_DEPT'])
#         return score

#     def match_cases_controls(self, df):
#         df_temoins = df[df['statut_deces_a_letude'] == 'non'].copy()
#         df_cas = df[df['statut_deces_a_letude'] == 'oui'].copy()
        
#         df_cas['date_reference'] = pd.to_datetime(df_cas['date_derniere_nouvelle'])
        
#         print(f"Cas: {len(df_cas)}")
#         print(f"T√©moins: {len(df_temoins)}")
        
#         dates_ref_temoins = []
#         temoin_cas_ids = []
        
#         for i, temoin in df_temoins.iterrows():
#             subset = df_cas[
#                 (df_cas['age_a_letude'] >= temoin['age_a_letude'] - 3) &
#                 (df_cas['age_a_letude'] <= temoin['age_a_letude'] + 3)
#             ].copy()
        
#             if len(subset) > 0:
#                 subset_sexe = subset[subset['patient_sexe'] == temoin['patient_sexe']]
#                 if len(subset_sexe) > 0:
#                     subset = subset_sexe
        
#             if len(subset) > 0:
#                 subset_patho = subset[subset['patho'] == temoin['patho']]
#                 if len(subset_patho) > 0:
#                     subset = subset_patho
        
#             if len(subset) > 0:
#                 scores = []
#                 cas_indices = []
        
#                 for idx, cas_row in subset.iterrows():
#                     score = self.score_matching(cas_row, temoin)
#                     scores.append(score)
#                     cas_indices.append(idx)
        
#                 best_idx = np.argmin(scores)
#                 chosen_case_idx = cas_indices[best_idx]
#                 chosen_case = df_cas.loc[chosen_case_idx]
        
#                 date_ref = chosen_case['date_reference']
#                 cas_id = chosen_case['pseudo_provisoire']
#             else:
#                 print(f"Aucun appariement trouv√© pour le t√©moin {i}, utilisation d'une date al√©atoire")
#                 # sampled_case = df_cas.sample(1)
#                 # date_ref = pd.to_datetime(sampled_case['date_reference'].values[0])
#                 # cas_id = sampled_case['pseudo_provisoire'].values[0]
        
#             dates_ref_temoins.append(date_ref)
#             temoin_cas_ids.append(cas_id)
        
#         # === Une fois la boucle termin√©e, ajouter les colonnes ===
#         df_temoins['date_reference'] = pd.to_datetime(dates_ref_temoins)
#         df_temoins['cas_apparie'] = temoin_cas_ids

        
#         # ========== √âtape 3 : Ajouter la colonne statut_deces ==========
#         # df_cas['statut_deces'] = 1
#         # df_temoins['statut_deces'] = 0
        
#         # ========== √âtape 4 : Concat√©ner ==========
#         df_all = pd.concat([df_cas, df_temoins], ignore_index=True)
        
#         print(f"\nDataset final: {len(df_all)} observations")
#         print(f"- Cas: {len(df_cas)}")
#         print(f"- T√©moins: {len(df_temoins)}")
        
#         # ========== V√©rification de l'appariement ==========
#         print("\n=== V√©rification de l'appariement ===")
        
#         # √Çge
#         print("\nDistribution des √¢ges:")
#         print("Cas:")
#         print(df_cas['age_a_letude'].describe())
#         print("T√©moins:")
#         print(df_temoins['age_a_letude'].describe())
        
#         # Sexe
#         print("\nDistribution par sexe:")
#         print("Cas:")
#         print(df_cas['patient_sexe'].value_counts())
#         print("T√©moins:")
#         print(df_temoins['patient_sexe'].value_counts())
        
#         # Pathologie
#         print("\nDistribution par pathologie:")
#         print("Cas:")
#         print(df_cas['patho'].value_counts())
#         print("T√©moins:")
#         print(df_temoins['patho'].value_counts())
        
#         # Dates anormales
#         print("\nDates de r√©f√©rence des t√©moins hors limites attendues (> 2020):")
#         print(df_temoins[df_temoins['date_reference'].dt.year > 2020][['pseudo_provisoire', 'date_reference', 'cas_apparie']])
    
#         return df_all

