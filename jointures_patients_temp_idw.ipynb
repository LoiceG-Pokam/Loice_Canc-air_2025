{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1015692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation IDW : 36 groupes (années x mois)\n",
      "⏩ 2017-01 déjà traité, on saute.\n",
      "⏩ 2017-02 déjà traité, on saute.\n",
      "⏩ 2017-03 déjà traité, on saute.\n",
      "⏩ 2017-04 déjà traité, on saute.\n",
      "⏩ 2017-05 déjà traité, on saute.\n",
      "⏩ 2017-06 déjà traité, on saute.\n",
      "⏩ 2017-07 déjà traité, on saute.\n",
      "⏩ 2017-08 déjà traité, on saute.\n",
      "⏩ 2017-09 déjà traité, on saute.\n",
      "⏩ 2017-10 déjà traité, on saute.\n",
      "⏩ 2017-11 déjà traité, on saute.\n",
      "⏩ 2017-12 déjà traité, on saute.\n",
      "⏩ 2018-01 déjà traité, on saute.\n",
      "⏩ 2018-02 déjà traité, on saute.\n",
      "⏩ 2018-03 déjà traité, on saute.\n",
      "⏩ 2018-04 déjà traité, on saute.\n",
      "⏩ 2018-05 déjà traité, on saute.\n",
      "⏩ 2018-06 déjà traité, on saute.\n",
      "⏩ 2018-07 déjà traité, on saute.\n",
      "⏩ 2018-08 déjà traité, on saute.\n",
      "⏩ 2018-09 déjà traité, on saute.\n",
      "⏩ 2018-10 déjà traité, on saute.\n",
      "⏩ 2018-11 déjà traité, on saute.\n",
      "⏩ 2018-12 déjà traité, on saute.\n",
      "⏩ 2019-01 déjà traité, on saute.\n",
      "Traitement 2019-02 avec 28 jours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpolation 2019-02: 100%|██████████| 28/28 [1:25:15<00:00, 182.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier NetCDF sauvegardé : R:/Direction_Data/0_Projets/Projet_CANCAIR/2025_Projet_Loice/temperatures_interpolated_IDW_NetCDF\\temperature_IDW_2019_02.nc\n",
      "Traitement 2019-03 avec 31 jours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpolation 2019-03: 100%|██████████| 31/31 [2:46:21<00:00, 321.99s/it] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\api.py:1928\u001b[0m, in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[1;32m-> 1928\u001b[0m     dump_to_store(\n\u001b[0;32m   1929\u001b[0m         dataset, store, writer, encoding\u001b[38;5;241m=\u001b[39mencoding, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[0;32m   1930\u001b[0m     )\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\api.py:1975\u001b[0m, in \u001b[0;36mdump_to_store\u001b[1;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m   1973\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[1;32m-> 1975\u001b[0m store\u001b[38;5;241m.\u001b[39mstore(variables, attrs, check_encoding, writer, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\common.py:458\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[1;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n\u001b[1;32m--> 458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_variables(\n\u001b[0;32m    459\u001b[0m     variables, check_encoding_set, writer, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[0;32m    460\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\common.py:500\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.set_variables\u001b[1;34m(self, variables, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[0;32m    496\u001b[0m target, source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_variable(\n\u001b[0;32m    497\u001b[0m     name, v, check, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[0;32m    498\u001b[0m )\n\u001b[1;32m--> 500\u001b[0m writer\u001b[38;5;241m.\u001b[39madd(source, target)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\common.py:345\u001b[0m, in \u001b[0;36mArrayWriter.add\u001b[1;34m(self, source, target, region)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     target[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m source\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:82\u001b[0m, in \u001b[0;36mBaseNetCDF4Array.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m     81\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m data[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mautoclose:\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:5519\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:5802\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2034\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: NetCDF: HDF error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 174\u001b[0m\n\u001b[0;32m    172\u001b[0m     out_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature_IDW_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m     out_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, out_filename)\n\u001b[1;32m--> 174\u001b[0m     ds\u001b[38;5;241m.\u001b[39mto_netcdf(out_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNETCDF4\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplevel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m}})\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Fichier NetCDF sauvegardé : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Tous les mois non traités ont été générés.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\core\\dataset.py:2021\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[1;32m-> 2021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_netcdf(  \u001b[38;5;66;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2023\u001b[0m     path,\n\u001b[0;32m   2024\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   2025\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m   2026\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m   2027\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2028\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   2029\u001b[0m     unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims,\n\u001b[0;32m   2030\u001b[0m     compute\u001b[38;5;241m=\u001b[39mcompute,\n\u001b[0;32m   2031\u001b[0m     multifile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2032\u001b[0m     invalid_netcdf\u001b[38;5;241m=\u001b[39minvalid_netcdf,\n\u001b[0;32m   2033\u001b[0m     auto_complex\u001b[38;5;241m=\u001b[39mauto_complex,\n\u001b[0;32m   2034\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\api.py:1944\u001b[0m, in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multifile \u001b[38;5;129;01mand\u001b[39;00m compute:  \u001b[38;5;66;03m# type: ignore[redundant-expr]\u001b[39;00m\n\u001b[1;32m-> 1944\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compute:\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:597\u001b[0m, in \u001b[0;36mNetCDF4DataStore.close\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:234\u001b[0m, in \u001b[0;36mCachingFileManager.close\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    232\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, default)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m     file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2627\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.close\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2590\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset._close\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2034\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pyproj import Transformer\n",
    "import xarray as xr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======== Fonctions auxiliaires ========\n",
    "def idw_interpolation(points, values, grid_points, power=2, smoothing=0, max_distance=None, min_neighbors=3, max_neighbors=12):\n",
    "    distances = cdist(grid_points, points, metric='euclidean')\n",
    "    interpolated = np.full(grid_points.shape[0], np.nan)\n",
    "\n",
    "    for i in range(grid_points.shape[0]):\n",
    "        dist_to_point = distances[i, :]\n",
    "        if max_distance is not None:\n",
    "            valid_mask = dist_to_point <= max_distance\n",
    "            if not np.any(valid_mask):\n",
    "                continue\n",
    "            dist_to_point = dist_to_point[valid_mask]\n",
    "            point_values = values[valid_mask]\n",
    "        else:\n",
    "            point_values = values\n",
    "\n",
    "        if len(dist_to_point) > max_neighbors:\n",
    "            nearest_indices = np.argsort(dist_to_point)[:max_neighbors]\n",
    "            dist_to_point = dist_to_point[nearest_indices]\n",
    "            point_values = point_values[nearest_indices]\n",
    "\n",
    "        if len(dist_to_point) < min_neighbors:\n",
    "            continue\n",
    "\n",
    "        dist_to_point = dist_to_point + smoothing\n",
    "        weights = 1.0 / (dist_to_point ** power)\n",
    "        weights /= np.sum(weights)\n",
    "        interpolated[i] = np.sum(weights * point_values)\n",
    "\n",
    "    return interpolated\n",
    "\n",
    "def adaptive_idw_parameters(points, extent, resolution):\n",
    "    area = (extent[2] - extent[0]) * (extent[3] - extent[1])\n",
    "    density = len(points) / (area / 1e6)\n",
    "\n",
    "    if density > 5:\n",
    "        power = 1.2\n",
    "        max_distance = 20000\n",
    "        min_neighbors = 3\n",
    "        max_neighbors = 6\n",
    "    elif density > 2:\n",
    "        power = 1.0\n",
    "        max_distance = 30000\n",
    "        min_neighbors = 3\n",
    "        max_neighbors = 8\n",
    "    else:\n",
    "        power = 0.8\n",
    "        max_distance = 60000\n",
    "        min_neighbors = 2\n",
    "        max_neighbors = 12\n",
    "\n",
    "    return power, max_distance, min_neighbors, max_neighbors\n",
    "\n",
    "# ======== Paramètres généraux ========\n",
    "df_temp = pd.read_csv(\"C:/temperature_ile_de_france.csv\", sep=\";\")\n",
    "df_temp[\"date\"] = pd.to_datetime(df_temp['date'])\n",
    "df_temp = df_temp[df_temp[\"date\"].dt.year.isin([2017, 2018, 2019])]\n",
    "df_temp = df_temp[(df_temp['temperature'] > -25) & (df_temp['temperature'] < 60)].copy()\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:2154\", always_xy=True)\n",
    "df_temp[['x', 'y']] = df_temp.apply(lambda row: pd.Series(transformer.transform(row['longitude'], row['latitude'])), axis=1)\n",
    "\n",
    "gdf = gpd.read_file(\"data/shapefile/IDF.shp\").to_crs(\"EPSG:2154\")\n",
    "extent = gdf.total_bounds\n",
    "\n",
    "res = 50\n",
    "x_min, y_min, x_max, y_max = extent\n",
    "x_coords = np.arange(x_min, x_max, res)\n",
    "y_coords = np.arange(y_min, y_max, res)\n",
    "grid_x, grid_y = np.meshgrid(x_coords, y_coords)\n",
    "grid_points = np.column_stack([grid_x.ravel(), grid_y.ravel()])\n",
    "\n",
    "nodata_value = np.nan\n",
    "output_dir = \"R:/Direction_Data/0_Projets/Projet_CANCAIR/2025_Projet_Loice/temperatures_interpolated_IDW_NetCDF\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ======== Détection des fichiers déjà générés ========\n",
    "done_months = set()\n",
    "for fname in os.listdir(output_dir):\n",
    "    if fname.startswith(\"temperature_IDW_\") and fname.endswith(\".nc\"):\n",
    "        try:\n",
    "            parts = fname.split(\"_\")\n",
    "            year = int(parts[2])\n",
    "            month = int(parts[3][:2])\n",
    "            done_months.add((year, month))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# ======== Traitement ========\n",
    "df_temp['year'] = df_temp['date'].dt.year\n",
    "df_temp['month'] = df_temp['date'].dt.month\n",
    "grouped = df_temp.groupby(['year', 'month'])\n",
    "\n",
    "print(f\"Interpolation IDW : {len(grouped)} groupes (années x mois)\")\n",
    "\n",
    "for (year, month), df_month in grouped:\n",
    "    if (year, month) in done_months:\n",
    "        print(f\"⏩ {year}-{month:02d} déjà traité, on saute.\")\n",
    "        continue\n",
    "\n",
    "    unique_dates = sorted(df_month['date'].dt.date.unique())\n",
    "    print(f\"Traitement {year}-{month:02d} avec {len(unique_dates)} jours\")\n",
    "\n",
    "    data_3d = np.full((len(unique_dates), grid_y.shape[0], grid_x.shape[1]), np.nan, dtype=np.float32)\n",
    "\n",
    "    for i, date in enumerate(tqdm(unique_dates, desc=f\"Interpolation {year}-{month:02d}\")):\n",
    "        df_day = df_month[df_month['date'].dt.date == date]\n",
    "        if len(df_day) < 2:\n",
    "            continue\n",
    "\n",
    "        points = df_day[['x', 'y']].values\n",
    "        values = df_day['temperature'].values\n",
    "\n",
    "        power, max_distance, min_neighbors, max_neighbors = adaptive_idw_parameters(points, extent, res)\n",
    "\n",
    "        grid_temp_flat = idw_interpolation(\n",
    "            points=points,\n",
    "            values=values,\n",
    "            grid_points=grid_points,\n",
    "            power=power,\n",
    "            smoothing=100.0,\n",
    "            max_distance=max_distance,\n",
    "            min_neighbors=min_neighbors,\n",
    "            max_neighbors=max_neighbors\n",
    "        )\n",
    "\n",
    "        grid_temp = grid_temp_flat.reshape(grid_y.shape)\n",
    "\n",
    "        sigma = 2.0 if len(df_day) > 10 else 1.0\n",
    "        grid_temp_smooth = gaussian_filter(grid_temp, sigma=sigma, mode='nearest')\n",
    "\n",
    "        valid_mask = ~np.isnan(grid_temp)\n",
    "        grid_temp = np.where(valid_mask, grid_temp_smooth, grid_temp)\n",
    "        grid_temp = np.clip(grid_temp, -25, 60)\n",
    "\n",
    "        data_3d[i, :, :] = grid_temp\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"temperature\": ([\"time\", \"y\", \"x\"], data_3d)\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": pd.to_datetime(unique_dates),\n",
    "            \"x\": x_coords,\n",
    "            \"y\": y_coords\n",
    "        },\n",
    "        attrs={\n",
    "            \"description\": \"Températures interpolées par IDW (journalières)\",\n",
    "            \"crs\": \"EPSG:2154\",\n",
    "            \"units\": \"°C\",\n",
    "            \"nodata\": nodata_value\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ds.x.attrs['units'] = 'meters'\n",
    "    ds.y.attrs['units'] = 'meters'\n",
    "    ds.time.attrs['standard_name'] = 'time'\n",
    "    ds.time.attrs['long_name'] = 'Date'\n",
    "\n",
    "    out_filename = f\"temperature_IDW_{year}_{month:02d}.nc\"\n",
    "    out_path = os.path.join(output_dir, out_filename)\n",
    "    ds.to_netcdf(out_path, mode='w', format='NETCDF4', encoding={\"temperature\": {\"zlib\": True, \"complevel\": 5}})\n",
    "\n",
    "    print(f\"✅ Fichier NetCDF sauvegardé : {out_path}\")\n",
    "\n",
    "print(\"✅ Tous les mois non traités ont été générés.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FONCTION BONUS : VALIDATION CROISÉE =====\n",
    "def cross_validation_idw(df_day, power=2, max_distance=25000, k_folds=5):\n",
    "    \"\"\"\n",
    "    Validation croisée pour évaluer la qualité de l'interpolation IDW\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    points = df_day[['x', 'y']].values\n",
    "    values = df_day['temperature'].values\n",
    "    \n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    errors = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(points):\n",
    "        train_points = points[train_idx]\n",
    "        train_values = values[train_idx]\n",
    "        test_points = points[test_idx]\n",
    "        test_values = values[test_idx]\n",
    "        \n",
    "        # Interpoler aux points de test\n",
    "        predicted = idw_interpolation(\n",
    "            train_points, train_values, test_points,\n",
    "            power=power, max_distance=max_distance\n",
    "        )\n",
    "        \n",
    "        # Calculer l'erreur\n",
    "        valid_mask = ~np.isnan(predicted)\n",
    "        if np.any(valid_mask):\n",
    "            mae = np.mean(np.abs(predicted[valid_mask] - test_values[valid_mask]))\n",
    "            errors.append(mae)\n",
    "    \n",
    "    return np.mean(errors) if errors else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc965036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de la validation croisée (décommenter pour tester)\n",
    "test_date = unique_dates[0]\n",
    "df_test = df[df['date'].dt.date == test_date]\n",
    "if len(df_test) >= 10:\n",
    "    mae = cross_validation_idw(df_test)\n",
    "    print(f\"Erreur moyenne absolue (validation croisée) : {mae:.2f}°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
